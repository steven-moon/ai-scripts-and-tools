# LLM Provider Settings
# Valid providers: local, openai, anthropic, gemini, custom
LLM_PROVIDER=local

# General Settings
LLM_MODEL=
LLM_TEMPERATURE=0.5
LLM_MAX_TOKENS=500

# Code Summary Generator Settings
# Comma-separated list of glob patterns to ignore when generating code summaries
CODE_SUMMARY_IGNORE_PATTERNS=node_modules/**,dist/**,*.log,**/test/**,**/tests/**,**/*.test.*,**/*.spec.*

# OpenAI Settings
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_ENDPOINT=https://api.openai.com/v1/completions
OPENAI_DEFAULT_MODEL=gpt-4o-2024-08-06
# OPENAI Model examples: gpt-3.5-turbo-instruct, gpt-4-turbo-preview

# Anthropic Settings
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_ENDPOINT=https://api.anthropic.com/v1/messages
ANTHROPIC_DEFAULT_MODEL=claude-3-sonnet-20240229
# ANTHROPIC Model examples: claude-3-sonnet-20240229, claude-3-opus-20240229

# Google Gemini Settings
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_ENDPOINT=https://generativelanguage.googleapis.com/v1
GEMINI_DEFAULT_MODEL=grok-2-1212
# GEMINI Model examples: gemini-1.5-flash, gemini-1.5-pro, gemini-2.0-flash

# Local LLM Settings (Ollama, LM Studio, etc.)
LOCAL_LLM_ENDPOINT=http://127.0.0.1:1234/v1/completions
LOCAL_LLM_MODEL=llama-3.2-3b-instruct

# Custom Provider Settings (OpenAI API Compatible)
CUSTOM_PROVIDER_NAME=My Custom LLM
CUSTOM_API_KEY=your_custom_api_key_here
CUSTOM_ENDPOINT=https://your-custom-endpoint.com/v1/completions
CUSTOM_DEFAULT_MODEL=your-custom-model-name 